{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Trending Predictions\n",
    "\n",
    "## Group Member Names\n",
    "- Zytal Lenus\n",
    "- Sharai Barrera\n",
    "- Kelly Chang\n",
    "- Victorionna Tran\n",
    "- Gina Oceguedar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "One of the most popular and influential social media platforms worldwide today is YouTube. The platform serves endless purposes such as; entertainment, marketing, video storage, news, and education. With a platform used by billions of people around the globe there are many videos shared every second and it is up to Machine Learning algorithms to regulate that content. Constantly researching how well these algorithms are at analyzing and predicting content is essential for YouTube to improve their models and for users to improve their content. New findings will help keep YouTube a successful platform to keep them in business.\n",
    "Prior research has analyzed which Machine Learning prediction models are best at predicting how long it would take a video to trend and also how long that video will last on the trending list. A specific study analyzed how YouTube’s interactive features play a role in helping a video trend. The features include comments, views, likes, suggested videos linked, date uploaded, and disabled features. The results from this study shows that the models that are best at predicting a video’s trending aspects are Logistic Regression, Random Forest, and Support Vector Machine classifiers. In addition, logarithmic miner regression is also a good model to use for supervised datasets. Some limitations to consider from this study for future research is that deep learning could not be implemented and they also kept in mind that the initial data set used is limited because it may not be generalizable to all content.\n",
    "Another data science study observed characteristics of trending videos in 2019, knowing these characteristics can be useful for YouTubers to keep in mind when uploading content and will help strengthen prediction models. On average, videos that trended were more likely to be uploaded on a Tuesday vs a Saturday and to be uploaded around noon vs the morning in eastern time. An interesting observation is that videos trend on average 5.6 days after uploading but usually no longer than 13 days after they’re uploaded. Aside from time, titles of trending videos were also taken into consideration, the characterizations found were that the average length was 36-64 characters with half of the titles being in all caps and “official” was the most common word found in them. The last characteristic to note is that tags showed a positive correlation with a video trending, on average 21 tags were used per trending video. This data is limited to 2019 and future studies can observe how these characterizations change over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "  Youtube’s algorithm has constantly been scrutinized in the past few years. Many creators and viewers complain that the algorithm set in place has biases and doesn’t truly reflect the content that is “trending”. Which is why we want to dive into Youtube trending data to see if there are any obvious underlying patterns.\n",
    "  \n",
    "  We are trying to observe any pattern in the Youtube trending algorithm. Our main goal is to predict how likely a video is to get onto the trend page. We intend on observing past patterns and using those patterns to predict how likely it is for it to trend based on certain features. We want to take into account features that people can manipulate (title, tags, and description) to see if certain text inputs might increase your chance of landing on the trending page. Additionally we would like to see if other quantitative variables, that aren't always directly malleable, reflect any patterns that are impactful on the likeliness of a video being placed on the trending page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "This dataset is a record of the top 200 trending videos from November 2017 to March 2018 <a name=\"kaggle\"></a>[<sup>[4]</sup>](#kagglenote). There are 23 variables available in the dataset and the total number of observations is 4,547. The variables for this data range from categorical to numerical.Each observation represents a trending video that was published and records a multitude of values associated with that specific video. Variables like the title, description, channel publisher, description, etc are all included.Some of the critical variables relate to the text of the trending video. Variables like the title, tags, and description of each video were the main subject of text analysis. They were represented using a word cloud extension in order to see the popularity of certain words/phrases. Other critical variables are the variables that are more quantitative as they will be used towards our regression exploration. \n",
    "\n",
    "## Cleaning \n",
    "A basic clean up was performed at the beginning of obtaining the dataset (general format fitting of the csv). A major clean up process was removing null values of the dataset to make sure the data we are working with has all the variables relating to that video. But for columns 'description' and 'tags' the null values weren't removed. Rather, those null values were replaced with a phrase indicating that it was blank since that was the intention of the video publisher. These cleanup processes are conducted and included in the beginning of each data clean up file.\n",
    "[LINEAR REGRESSION SUMMARY]\n",
    "The folder specified “Data Clean Up” contains all the code we used in our data processing <a name=\"github\"></a>[<sup>[5]</sup>](#githubnote). One file uses the sklearn count vectorizer function for text analysis by converting a collection of text documents to a matrix of token counts. Then a model was run using those features again utilizing functions primarily from sklearn.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Based on prior research on trending videos, specifically the aforementioned study on Youtube’s interactive features and how they can contribute to a video trending, we decided that linear regression would be best to represent our data analysis. Although background research has suggested that logistic regression be a useful method in studying predicting video popularity, we ultimately did not decide on that because logistic regressions are used for classification, while our purpose is to predict a continuous outcome. Using a linear regression, we can predict the count of multiple variables based on the number of views that videos received. Cross comparison of these plots would help us come to conclusions of what factors in our dataset would be most affected by views, and possibly also draw hypotheses on what makes a video trending. Because we have multiple variables that we are comparing, it would be best to use adjusted R squared and capture the most accurate view of correlation relationships for each dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For this project, we plan to use a regression model to predict if a video will trend based features of previous trending videos. Therefore, the evaluation metrics we will be using are R squared and Mean Squared Error.\n",
    "\n",
    "### R squared:\n",
    "R squared determines variance in the dependent variable represented by the independent variables collectively. \n",
    "\n",
    "$$ \\begin{align*}R^{2} = 1-\\frac{SS_{res}}{SS_{tot}}\\end{align*}$$\n",
    "\n",
    "#### Total Sum of Squares ($SS_{tot}$):\n",
    "$$\\begin{align*}SS_{tot} = \\sum_{i}^{}(y_{i}-\\overline{y})^{2} \\end{align*}$$\n",
    "$$\\begin{align*}y_{i} = \\text{i-th value in a sample}\\end{align*}$$\n",
    "$$\\begin{align*}\\overline{y} = \\text{mean value of a sample}\\end{align*}$$\n",
    "\n",
    "#### Residual Sum of Squares ($SS_{res}$)\n",
    "$$ \\begin{align*}SS_{res} = \\sum_{i}^{}(y_{i}-{f}_{i})^{2} = \\sum_{i}^{}e_{i}^{2} \\end{align*}$$\n",
    "\n",
    "$$\\begin{align*}y_{i} = \\text{i-th value of the variable to be predicted}\\end{align*}$$\n",
    "$$\\begin{align*}f_{i} = \\text{predicted value of }y_{i}\\end{align*}$$\n",
    "\n",
    "### Mean Squared Error:\n",
    "Mean squared error determines the average squared difference between observed and predicted values. \n",
    "\n",
    "$$\\begin{align*}MSE = \\frac{1}{n}\\sum_{i}^{n}(\\widehat{y}_{i}-y_{i})^{2}\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*}n = \\text{number of data points}\\end{align*}$$\n",
    "$$\\begin{align*}\\widehat{y}_{i} = \\text{predicted values}\\end{align*}$$\n",
    "$$\\begin{align*}{y}_{i} = \\text{observed values}\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Data Analysis\n",
    "#### Trending Day Count vs Days It Takes to Trend After Published\n",
    "<img src=\"trend_day_count vs trend.publish.diff.png\">\n",
    "\n",
    "There is a positive slope indicating that videos that ended up trending on a later date, trended for longer. This implies that a video is most likely to trend and trend for a longer duration if it trends within 22-45 days after it's published date.\n",
    "\n",
    "#### Trending Day Count vs Views\n",
    "<img src=\"trend_day_count vs views.png\">\n",
    "\n",
    "There is a positive slope indicating that the more views a video has, the longer it trends. This implies that a video is most likely to trend and trend for longer if it can accumulatte a high number of views. This makes sense since a video that trended for a longer period of time is more likely to catch the attention of more viewers.\n",
    "\n",
    "#### Publish Hour vs Views\n",
    "<img src=\"views vs publish_hour.png\">\n",
    "\n",
    "There is a slight negative slope at around the 15:00 time mark, implying that a video is more likely to trend if it is posted earlier than 15:00 (3PM). This may be due to the fact that   \n",
    "\n",
    "#### Subscriber Count vs Trending Day Count\n",
    "<img src = \"subscriber vs trend_day_count.png\">\n",
    "There is a negative slope indicating that a trending video trends for a shorter duration the more subscribers a channel has. This implies that a channel does not need a large amount of followers in order for their videos to trend longer.This is probably because videos that trend for long periods of time are most likely shared amongst the general public, attracting viewers that are not particularly fans of the creators. In comparison, the Subcriber Count vs Days It Takes to Trend After Published has a negative slope but implies that the more subscribers a channel has the faster it is to trend after it is published. This could be because subscribers are the first to be notified when a channel publishes a video.\n",
    "\n",
    "\n",
    "### Feature Selection \n",
    "\n",
    "In order to decide on which variables would be best to run against each other in a linear regression model, we read the description of each variable provided by the data set and hypothesized which variables would most likely contribute to a video ending up on the trending page before testing. \n",
    "\n",
    "For each of the variables we chose to run against each other in linear regression, we also made a box plot of the variables to see the variability of the data. We then used the interquartile range of the variable with the largest data range to do linear regression on with the other variable. We did this in order to avoid the outliers' affect on the linear regression graph. \n",
    "Further details and visualization can be found: <a href= \"https://github.com/COGS118A/Group035-Sp22/tree/main/Data%20Clean%20Up\"> FinalProject_DataExploration.ipynb</a>\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?\n",
    "\n",
    "Some limitations with our research project lie specifically with the data available to us. The data that we used is from 2017/2018 which is approximately 4 years ago. Since Youtube is a platform that is constantly changing and pushing updates the analysis we conducted was on numbers that are outdated in terms of this type of platform. We can expect that with the continuation of time it is expected that if we want more accurate predictions we have to use more recent data as that would be more relevant to the present.\n",
    "\n",
    "Another limitation is the size of the data we can use. Given the resources available to us at the moment working with a dataset that is too large or too computationally advanced is not likely due to the processing power we have available to us at the moment. To make better predictions we would want larger datasets but computation is out of reach.\n",
    "\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "Aside from the factors we intend to use for this project, there may be many other factors that contribute to a video trending that we can not evaluate from the given dataset. Such factors may include promotion of a video on other media or physical platforms and the outreach power of its promoters.\n",
    "For our project we intend to honor all anonymity and provide no information regarding the identity of the users. Most of the data we plan on using has already filtered out usernames/personal information. But we additionally plan to re-evaluate and filter out the data. Additionally, our project is intended only for educational purposes and will not and should not be used for commercial purposes.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"niturenote\"></a>1.[^](#niture): “Niture,A. (2020-2021). Predictive analysis of YouTube trending videos using Machine Learning. https://esource.dbs.ie/bitstream/handle/10788/4260/msc_niture_aa_2021.pdf?sequence=1&isAllowed=y <br> \n",
    "<a name=\"hale\"></a>2.[^](#hale): “Hale, J. (2020) What Makes A YouTube Video Hit The Trending Tab? This Data Scientist Broke Down Every Single Video That Trended In 2019. https://www.tubefilter.com/2020/07/10/what-makes-a-youtube-video-trending-2019-ammar-alyousfi/amp/<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
