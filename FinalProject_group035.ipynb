{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Trending Predictions\n",
    "\n",
    "## Group Member Names\n",
    "- Zytal Lenus\n",
    "- Sharai Barrera\n",
    "- Kelly Chang\n",
    "- Victorionna Tran\n",
    "- Gina Oceguedar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "  Youtube’s algorithm has constantly been scrutinized in the past few years. Many creators and viewers complain that the algorithm set in place has biases and doesn’t truly reflect the content that is “trending”. Which is why we want to dive into Youtube trending data to see if there are any obvious underlying patterns.\n",
    "  \n",
    "  We are trying to observe any pattern in the Youtube trending algorithm. Our main goal is to predict how likely a video is to get onto the trend page. We intend on observing past patterns and using those patterns to predict how likely it is for it to trend based on certain features. We want to take into account features that people can manipulate (title, tags, and description) to see if certain text inputs might increase your chance of landing on the trending page. Additionally we would like to see if other quantitative variables, that aren't always directly malleable, reflect any patterns that are impactful on the likeliness of a video being placed on the trending page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "This dataset is a record of the top 200 trending videos from November 2017 to March 2018 <a name=\"kaggle\"></a>[<sup>[4]</sup>](#kagglenote). There are 23 variables available in the dataset and the total number of observations is 4,547. The variables for this data range from categorical to numerical.Each observation represents a trending video that was published and records a multitude of values associated with that specific video. Variables like the title, description, channel publisher, description, etc are all included.Some of the critical variables relate to the text of the trending video. Variables like the title, tags, and description of each video were the main subject of text analysis. They were represented using a word cloud extension in order to see the popularity of certain words/phrases. Other critical variables are the variables that are more quantitative as they will be used towards our regression exploration. \n",
    "\n",
    "## Cleaning \n",
    "A basic clean up was performed at the beginning of obtaining the dataset (general format fitting of the csv). A major clean up process was removing null values of the dataset to make sure the data we are working with has all the variables relating to that video. But for columns 'description' and 'tags' the null values weren't removed. Rather, those null values were replaced with a phrase indicating that it was blank since that was the intention of the video publisher. These cleanup processes are conducted and included in the beginning of each data clean up file.\n",
    "[LINEAR REGRESSION SUMMARY]\n",
    "The folder specified “Data Clean Up” contains all the code we used in our data processing <a name=\"github\"></a>[<sup>[5]</sup>](#githubnote). One file uses the sklearn count vectorizer function for text analysis by converting a collection of text documents to a matrix of token counts. Then a model was run using those features again utilizing functions primarily from sklearn.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?\n",
    "\n",
    "Some limitations with our research project lie specifically with the data available to us. The data that we used is from 2017/2018 which is approximately 4 years ago. Since Youtube is a platform that is constantly changing and pushing updates the analysis we conducted was on numbers that are outdated in terms of this type of platform. We can expect that with the continuation of time it is expected that if we want more accurate predictions we have to use more recent data as that would be more relevant to the present.\n",
    "\n",
    "Another limitation is the size of the data we can use. Given the resources available to us at the moment working with a dataset that is too large or too computationally advanced is not likely due to the processing power we have available to us at the moment. To make better predictions we would want larger datasets but computation is out of reach.\n",
    "\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem<br>\n",
    "<a name=\"kagglenote\"></a>4.[^](#kaggle): “YouTube Trending Video Statistics with Subscriber.” Kaggle, https://www.kaggle.com/datasets/sgonkaggle/youtube-trend-with-subscriber?select=USvideos_modified.csv <br>\n",
    "<a name=\"githubnote\"></a>5.[^](#github):“Group035-Sp22/Data Clean Up/.” COGS118A / Group035-Sp22, Github, https://github.com/COGS118A/Group035-Sp22/tree/main/Data%20Clean%20Up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
