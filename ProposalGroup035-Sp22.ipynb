{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Zytal Lenus\n",
    "- Sharai Barrera\n",
    "- Kelly Chang\n",
    "- Victorionna Tran\n",
    "- Gina Ocegueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our goal is to improve Youtube’s algorithms by preventing the cause of biases and instead find the patterns that can help predict what content is likely to trend or not. The data we are using represents different countries and are measured by variables ranging from categorical to numerical. One is the use of dates and when they trend. What we will be doing with the data is filtering them by their different variables to find out which dataset will be most useful for us. Our performance and success will be measured by being able to predict when and the factors of what makes something trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "One of the most popular and influential social media platforms world wide today is YouTube. The platform serves endless purposes such as; entertainment, marketing, video storage, news, and education. With a platform used by billions of people around the globe there are many videos shared every second and it is up to Machine Learning algorithms to regulate that content. Constantly researching how well these algorithms are at analyzing and predicting content is essential for YouTube to improve their models and for users to improve their content. New findings will help keep YouTube a successful platform to keep them in business.\n",
    "\n",
    "Prior research has analyzed which Machine Learning prediction models are best at predicting how long it would take a video to trend and also how long that video will last on the trending list. A specific study analyzed how YouTube’s interactive features play a role in helping a video trend. The features include comments, views, likes, suggested videos linked, date uploaded, and disabled features. The results from this study shows that the models that are best at predicting a video’s trending aspects are Logistic Regression, Random Forest, and Support Vector Machine classifiers. In addition, logarithmic miner regression is also a good model to use for supervised datasets. Some limitations to consider from this study for future research is that deep learning could not be implemented and they also kept in mind that the initial data set used is limited because it may not be generalizable to all content.\n",
    "\n",
    "Another data science study observed characteristics of trending videos in 2019, knowing these characteristics can be useful for YouTubers to keep in mind when uploading content and will help strengthen prediction models. On average videos that trended were more likely to be uploaded on a Tuesday vs a Saturday and to be uploaded around noon vs the morning in eastern time. An interesting observation is that videos trend on average 5.6 days after uploading but usually no longer than 13 days after they’re uploaded. Aside from time, titles of trending videos were also taken into consideration, the characterizations found were that the average length was 36-64 characters with half of the titles being in all caps and “official” was the most common word found in them. The last characteristic to note is that tags showed a positive correlation with a video trending, on average 21 tags were used per trending video. This data is limited to 2019 and future studies can observe how these characterizations change over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "  Youtube’s algorithm has constantly been scrutinized. Many creators and viewers complain that the algorithm set in place has biases and doesn’t truly reflect the content that is “trending”. Which is why we want to dive into Youtube trending data. \n",
    "    \n",
    "  We are trying to observe any pattern in the Youtube trending algorithm. Our main goal is to predict how likely a video is to get onto the trend page. We intend on observing past patterns and using those patterns to predict how likely it is for it to trend in different nations. We want to take into account the region, the text associated with the video, and potentially see if there are patterns based on the creator that pushes “trending” content out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- https://www.kaggle.com/datasets/datasnaek/youtube-new?select=USvideos.csv\n",
    "- There are 10 avaialble datasets for this topic, each dataset represents a certain country.\n",
    "- There are 16 variables available in each dataset and the total number of observations depends on what country or countries is being focused on (varying from 5,000-30,000+ dependent on the country). The variables for this data range from categorical to numerical.\n",
    "- The observations consist of information relating to the time of the trending video, the video title, its description, and general numerical performances of said video.\n",
    "- Some critical variables relate to the time and date of the trending video. For a text analysis, the critical videos would be the title and description of each video. For the representation of each of these variables it is dependent on how they were inputed. Meaning the text portions are represented in text format while the numerical data is stored as numerical quantities. \n",
    "- Special handling will be properly overlapping certain countries data. The data set provides information to at 10 countries so we have to filter out and see which dataset we are more interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To confirm or disconfirm the notion that YouTube trending videos are truly biased, we would essentially look for any patterns in the history of trending videos. Some variables that would be relevant to identifying these patterns are the category the video is under, any tags it has, time and location of posting, the channel it is posted under, and the title of the video. These factors could easily determine how much exposure the video gets, and how interesting the video appears to people, initiating engagement. We could also compare the views and likes to get an idea of the numerical value that trending videos hold. Sentiment analysis would help us study the affective states of our information, particularly useful in looking for patterns within the text of the video, where the data is more subjective/emotional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For this project, we plan to use a regression model. Therefore, one of the evaluation metrics we will be using is adjusted R squared. Additionally, we may also use a comparison model for sentiment analysis. In that case an evaluation metric for that would be accuracy/precision/recall. As we go forward with our project we will have a better grasp at which evaluation metrics would be best.\n",
    "\n",
    "#### Adjusted R Squared:\n",
    "Since there are various factors that contribute to a video on youtube trending, using adjusted R squared would be more accurate than using R squared, because adjusted R squared has the ability to test different independent variables against a model.\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "adjusted  R^{2} = 1-\\frac{(1-R^{2})(N-1)}{N-\\rho-1} \n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "$$\\begin{align*}R^{2} = Sample R Squared\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*} N = Total Sample Size \\end{align*} $$\n",
    "\n",
    "$$\\begin{align*}\\rho = Number of Independent Variable\\end{align*}$$\n",
    "\n",
    "#### Accuracy/Precision/Recall:\n",
    "Since sentiment analysis involves classification, accuracy/precision/recall evaluation metrics should be used.  \n",
    "$$ \\begin{align*}Accuracy = \\frac{(TP+TN)}{(TP+FP+FN+TN)}\\end{align*}$$\n",
    "\n",
    "$$ \\begin{align*}Precision = \\frac{(TP)}{(TP+FP)}\\end{align*}$$ \n",
    "\n",
    "$$ \\begin{align*}Recall = \\frac{(TP)}{(TP+FN)}\\end{align*}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the factors we intend to use for this project, there may be many other factors that contribute to a video trending that we can not evaluate from the given dataset. Such factors may include promotion of a video on other media or physical platforms and the outreach power of its promoters. \n",
    "\n",
    "For our project we intend to honor all anonymity and provide no information regarding the identity of the users. Most the data we plan on using has already filtered out usernames/personal information. But we additionally plan re-evaluate and filter out the data. Additionally, our project is intended only for educational purposes and will not and should not be used for commercial purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Expectation 1*: Every member participates and complete's their assigned task to the best of their ability\n",
    "* *Expectation 2*: Decisions will be made as a group\n",
    "* *Expecation 3*: Members should respect deadlines and inform the group of changes ahead of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/21  |  7 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 4/24  |  3 PM |  Do background research on topic  | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 4/24  | 3 PM  | Edit, finalize, and submit proposal; Search for datasets   | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/5   | 7 PM  | Import & Wrangle Data ,do some EDA  | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/13  | 7 PM  | Finalize wrangling/EDA; Begin programming for project  | Discuss/edit project code; Complete project |\n",
    "| 5/26  | 7 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 6/8  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"niturenote\"></a>1.[^](#niture): “Niture,A. (2020-2021). Predictive analysis of YouTube trending videos using Machine Learning. https://esource.dbs.ie/bitstream/handle/10788/4260/msc_niture_aa_2021.pdf?sequence=1&isAllowed=y <br> \n",
    "<a name=\"hale\"></a>2.[^](#hale): “Hale, J. (2020) What Makes A YouTube Video Hit The Trending Tab? This Data Scientist Broke Down Every Single Video That Trended In 2019. https://www.tubefilter.com/2020/07/10/what-makes-a-youtube-video-trending-2019-ammar-alyousfi/amp/<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
